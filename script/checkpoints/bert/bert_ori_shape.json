{
    "": {
        "in_shape": [
            [
                32,
                128,
                "torch.int64"
            ],
            [
                32,
                128,
                "torch.int64"
            ],
            [
                32,
                128,
                "torch.int64"
            ]
        ],
        "out_shape": [
            [
                32,
                2,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertForSequenceClassification'>"
    },
    "bert": {
        "in_shape": [
            [
                32,
                128,
                "torch.int64"
            ],
            [
                32,
                128,
                "torch.int64"
            ],
            [
                32,
                128,
                "torch.int64"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertModel'>"
    },
    "bert.embeddings": {
        "in_shape": [
            [
                32,
                128,
                "torch.int64"
            ],
            [
                32,
                128,
                "torch.int64"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertEmbeddings'>"
    },
    "bert.embeddings.word_embeddings": {
        "in_shape": [
            [
                32,
                128,
                "torch.int64"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                30522,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.sparse.Embedding'>"
    },
    "bert.embeddings.position_embeddings": {
        "in_shape": [
            [
                1,
                128,
                "torch.int64"
            ]
        ],
        "out_shape": [
            [
                1,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                512,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.sparse.Embedding'>"
    },
    "bert.embeddings.token_type_embeddings": {
        "in_shape": [
            [
                32,
                128,
                "torch.int64"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                2,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.sparse.Embedding'>"
    },
    "bert.embeddings.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.embeddings.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertEncoder'>"
    },
    "bert.encoder.layer": {
        "in_shape": [],
        "out_shape": [],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.container.ModuleList'>"
    },
    "bert.encoder.layer.0": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.0.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.0.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.0.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.0.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.0.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.0.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.0.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.0.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.0.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.0.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.0.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.0.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.0.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.0.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.0.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.0.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.1": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.1.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.1.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.1.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.1.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.1.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.1.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.1.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.1.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.1.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.1.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.1.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.1.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.1.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.1.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.1.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.1.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.2": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.2.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.2.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.2.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.2.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.2.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.2.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.2.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.2.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.2.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.2.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.2.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.2.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.2.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.2.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.2.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.2.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.3": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.3.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.3.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.3.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.3.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.3.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.3.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.3.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.3.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.3.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.3.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.3.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.3.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.3.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.3.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.3.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.3.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.4": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.4.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.4.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.4.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.4.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.4.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.4.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.4.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.4.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.4.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.4.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.4.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.4.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.4.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.4.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.4.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.4.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.5": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.5.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.5.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.5.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.5.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.5.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.5.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.5.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.5.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.5.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.5.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.5.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.5.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.5.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.5.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.5.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.5.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.6": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.6.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.6.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.6.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.6.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.6.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.6.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.6.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.6.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.6.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.6.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.6.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.6.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.6.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.6.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.6.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.6.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.7": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.7.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.7.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.7.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.7.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.7.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.7.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.7.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.7.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.7.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.7.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.7.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.7.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.7.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.7.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.7.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.7.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.8": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.8.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.8.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.8.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.8.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.8.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.8.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.8.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.8.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.8.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.8.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.8.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.8.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.8.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.8.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.8.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.8.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.9": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.9.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.9.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.9.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.9.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.9.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.9.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.9.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.9.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.9.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.9.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.9.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.9.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.9.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.9.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.9.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.9.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.10": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.10.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.10.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.10.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.10.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.10.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.10.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.10.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.10.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.10.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.10.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.10.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.10.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.10.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.10.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.10.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.10.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.11": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertLayer'>"
    },
    "bert.encoder.layer.11.attention": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertAttention'>"
    },
    "bert.encoder.layer.11.attention.self": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                1,
                1,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfAttention'>"
    },
    "bert.encoder.layer.11.attention.self.query": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.11.attention.self.key": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.11.attention.self.value": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.11.attention.self.dropout": {
        "in_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                12,
                128,
                128,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.11.attention.output": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertSelfOutput'>"
    },
    "bert.encoder.layer.11.attention.output.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.11.attention.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.11.attention.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.encoder.layer.11.intermediate": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertIntermediate'>"
    },
    "bert.encoder.layer.11.intermediate.dense": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                3072,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.11.output": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ],
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertOutput'>"
    },
    "bert.encoder.layer.11.output.dense": {
        "in_shape": [
            [
                32,
                128,
                3072,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                3072
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.encoder.layer.11.output.LayerNorm": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.normalization.LayerNorm'>"
    },
    "bert.encoder.layer.11.output.dropout": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "bert.pooler": {
        "in_shape": [
            [
                32,
                128,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'transformers.modeling_bert.BertPooler'>"
    },
    "bert.pooler.dense": {
        "in_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                768,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    },
    "bert.pooler.activation": {
        "in_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.activation.Tanh'>"
    },
    "dropout": {
        "in_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "weight_shape": [],
        "type": "<class 'torch.nn.modules.dropout.Dropout'>"
    },
    "classifier": {
        "in_shape": [
            [
                32,
                768,
                "torch.float32"
            ]
        ],
        "out_shape": [
            [
                32,
                2,
                "torch.float32"
            ]
        ],
        "weight_shape": [
            [
                2,
                768
            ]
        ],
        "type": "<class 'torch.nn.modules.linear.Linear'>"
    }
}