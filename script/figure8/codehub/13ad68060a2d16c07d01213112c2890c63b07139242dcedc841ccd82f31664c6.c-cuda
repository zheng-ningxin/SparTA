// GLOBALS: input0:int64[3] -> output0:int64[1]
// BACKEND: c-cuda (default)
// CONFIG: {"Foutput0:D0": [-1, 1, 1, 1], "Foutput0:O": [0], "Foutput0:S": 1, "Foutput0:R": 0}
// COMPUTE_V1: - einstein_v2(" output0[] = input0[0]; ", input_dict={ "input0" : { "dtype" : "int64", "shape" : [3]} })


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:int64[3] -> output0:int64[1]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#define __ITEM_0_OF__(v) (v).x
#define __ITEM_1_OF__(v) (v).y
#define __ITEM_2_OF__(v) (v).z
#define __ITEM_3_OF__(v) (v).w

#define __STORE_ITEM_0__(t, out, ido, in, idi) *(t*)(out + ido) = *(t*)(in + idi)
#define __STORE_ITEM_1__(t, out, ido, in, idi)
#define __STORE_ITEM_2__(t, out, ido, in, idi)
#define __STORE_ITEM_3__(t, out, ido, in, idi)

#define MAKE_VEC4_OP(type) \
  __forceinline__ __device__ type operator+(const type &l, const type &r) { return make_##type(l.x + r.x, l.y + r.y, l.z + r.z, l.w + r.w); } \
  __forceinline__ __device__ type operator-(const type &l, const type &r) { return make_##type(l.x - r.x, l.y - r.y, l.z - r.z, l.w - r.w); } \
  __forceinline__ __device__ type operator*(const type &l, const type &r) { return make_##type(l.x * r.x, l.y * r.y, l.z * r.z, l.w * r.w); } \
  __forceinline__ __device__ type operator/(const type &l, const type &r) { return make_##type(l.x / r.x, l.y / r.y, l.z / r.z, l.w / r.w); } \
  __forceinline__ __device__ type operator%(const type &l, const type &r) { return make_##type(l.x % r.x, l.y % r.y, l.z % r.z, l.w % r.w); }
#define MAKE_VEC2_OP(type) \
  __forceinline__ __device__ type operator+(const type &l, const type &r) { return make_##type(l.x + r.x, l.y + r.y); } \
  __forceinline__ __device__ type operator-(const type &l, const type &r) { return make_##type(l.x - r.x, l.y - r.y); } \
  __forceinline__ __device__ type operator*(const type &l, const type &r) { return make_##type(l.x * r.x, l.y * r.y); } \
  __forceinline__ __device__ type operator/(const type &l, const type &r) { return make_##type(l.x / r.x, l.y / r.y); } \
  __forceinline__ __device__ type operator%(const type &l, const type &r) { return make_##type(l.x % r.x, l.y % r.y); }

MAKE_VEC4_OP(int4)
MAKE_VEC2_OP(int2)

__forceinline__ __device__ __half max(const __half a, const __half b) { return a > b ? a : b; }
__forceinline__ __device__ __half min(const __half a, const __half b) { return a < b ? a : b; }

#endif


extern "C" __global__ __launch_bounds__(1) void template_op_kernel0(int64_t* __restrict__ input0, int64_t* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 1
  // [thread_extent] threadIdx.x = 1
  output0[(0)] = input0[(0)];
}

// Saved Perf = 1.806950e-06 sec / run; Step Produced = 925; Planned Steps = 1000;
// Antares Tuning Completed in 1000 steps.