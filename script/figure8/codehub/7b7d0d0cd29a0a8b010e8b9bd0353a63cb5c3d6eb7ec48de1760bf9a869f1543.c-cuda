// GLOBALS: input0:float32[416], input1:float32[32, 416, 7, 7] -> output0:float32[32, 416]
// BACKEND: c-cuda (default)
// CONFIG: {"Routput0:S": 0, "Routput0:R0": [-1, 7], "Routput0:W": 1, "Routput0:R1": [-1, 1], "Routput0:D0": [-1, 8], "Routput0:D1": [-1, 8]}
// COMPUTE_V1: - einstein_v2(" mediate0[N0, N1, N2, N3] = input0[N1] where N0 in 32, N2 in 7, N3 in 7;   mediate1[N0, N1, N2, N3] = input1[N0, N1, N2, N3] + mediate0[N0, N1, N2, N3]; mediate2[N0, N1, N2, N3] = mediate1[N0, N1, N2, N3].call(`max`, [const(0).cast(mediate1[N0, N1, N2, N3].dtype())]);output0[N0, N1] +=! mediate2[N0, N1, N2, N3]", input_dict={ "input0" : { "dtype" : "float32", "shape" : [416]} ,  "input1" : { "dtype" : "float32", "shape" : [32, 416, 7, 7]} }) ## @:  memcpy


// ---------------------------------------------------------------------------
// LOCAL: template_op_kernel0 -- input0:float32[416], input1:float32[32, 416, 7, 7] -> output0:float32[32, 416]

#include <cuda_runtime.h>
#include <cuda_fp16.h>
#include <mma.h>

#ifndef __CUDA_COMMON_MACRO__
#define __CUDA_COMMON_MACRO__

#define __ITEM_0_OF__(v) (v).x
#define __ITEM_1_OF__(v) (v).y
#define __ITEM_2_OF__(v) (v).z
#define __ITEM_3_OF__(v) (v).w

#define __STORE_ITEM_0__(t, out, ido, in, idi) *(t*)(out + ido) = *(t*)(in + idi)
#define __STORE_ITEM_1__(t, out, ido, in, idi)
#define __STORE_ITEM_2__(t, out, ido, in, idi)
#define __STORE_ITEM_3__(t, out, ido, in, idi)

#define MAKE_VEC4_OP(type) \
  __forceinline__ __device__ type operator+(const type &l, const type &r) { return make_##type(l.x + r.x, l.y + r.y, l.z + r.z, l.w + r.w); } \
  __forceinline__ __device__ type operator-(const type &l, const type &r) { return make_##type(l.x - r.x, l.y - r.y, l.z - r.z, l.w - r.w); } \
  __forceinline__ __device__ type operator*(const type &l, const type &r) { return make_##type(l.x * r.x, l.y * r.y, l.z * r.z, l.w * r.w); } \
  __forceinline__ __device__ type operator/(const type &l, const type &r) { return make_##type(l.x / r.x, l.y / r.y, l.z / r.z, l.w / r.w); } \
  __forceinline__ __device__ type operator%(const type &l, const type &r) { return make_##type(l.x % r.x, l.y % r.y, l.z % r.z, l.w % r.w); }
#define MAKE_VEC2_OP(type) \
  __forceinline__ __device__ type operator+(const type &l, const type &r) { return make_##type(l.x + r.x, l.y + r.y); } \
  __forceinline__ __device__ type operator-(const type &l, const type &r) { return make_##type(l.x - r.x, l.y - r.y); } \
  __forceinline__ __device__ type operator*(const type &l, const type &r) { return make_##type(l.x * r.x, l.y * r.y); } \
  __forceinline__ __device__ type operator/(const type &l, const type &r) { return make_##type(l.x / r.x, l.y / r.y); } \
  __forceinline__ __device__ type operator%(const type &l, const type &r) { return make_##type(l.x % r.x, l.y % r.y); }

MAKE_VEC4_OP(int4)
MAKE_VEC2_OP(int2)

#endif


extern "C" __global__ __launch_bounds__(448) void template_op_kernel0(float* __restrict__ input0, float* __restrict__ input1, float* __restrict__ output0) {
  // [thread_extent] blockIdx.x = 208
  // [thread_extent] threadIdx.y = 64
  // [thread_extent] threadIdx.x = 7
  float normal_reduce_temp0[1];
  __shared__ float red_buf0[448];
  normal_reduce_temp0[(0)] = 0.000000e+00f;
  for (int N2 = 0; N2 < 7; ++N2) {
    normal_reduce_temp0[(0)] = (normal_reduce_temp0[(0)] + max((input1[((((((((((int)blockIdx.x) / 52) * 163072) + ((((int)threadIdx.y) >> 3) * 20384)) + ((((int)blockIdx.x) % 52) * 392)) + ((((int)threadIdx.y) & 7) * 49)) + (N2 * 7)) + ((int)threadIdx.x)))] + input0[((((((int)blockIdx.x) % 52) * 8) + (((int)threadIdx.y) & 7)))]), 0.000000e+00f));
  }
  __syncthreads();
  ((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] = normal_reduce_temp0[(0)];
  __syncthreads();
  if (((int)threadIdx.x) < 3) {
    ((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] = (((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] + ((volatile float*)red_buf0)[((((((int)threadIdx.y) * 7) + ((int)threadIdx.x)) + 4))]);
  }
  __syncthreads();
  if (((int)threadIdx.x) < 2) {
    float w_2_0 = (((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] + ((volatile float*)red_buf0)[((((((int)threadIdx.y) * 7) + ((int)threadIdx.x)) + 2))]);
    ((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] = w_2_0;
    float w_1_0 = (((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] + ((volatile float*)red_buf0)[((((((int)threadIdx.y) * 7) + ((int)threadIdx.x)) + 1))]);
    ((volatile float*)red_buf0)[(((((int)threadIdx.y) * 7) + ((int)threadIdx.x)))] = w_1_0;
  }
  __syncthreads();
  output0[((((((((int)blockIdx.x) / 52) * 3328) + ((((int)threadIdx.y) >> 3) * 416)) + ((((int)blockIdx.x) % 52) * 8)) + (((int)threadIdx.y) & 7)))] = ((volatile float*)red_buf0)[((((int)threadIdx.y) * 7))];
}

// Saved Perf = 7.296690e-06 sec / run; Step Produced = 102; Planned Steps = 1000;
// Antares Tuning Completed in 1000 steps.